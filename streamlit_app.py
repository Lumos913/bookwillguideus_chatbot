import streamlit as st
import pandas as pd
from openai import OpenAI


# # ë°ì´í„°í”„ë ˆì„ ìƒì„± (CSV íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë¶€ë¶„ì„ í¬í•¨)
# def load_books():
#     df_loaded = pd.read_csv("yes24_bestsellers.csv", encoding="utf-8-sig")
#     return df_loaded

# # ì‚¬ìš©ì ì…ë ¥ì„ ì¹´í…Œê³ ë¦¬ë¡œ ë§¤ì¹­í•˜ëŠ” í•¨ìˆ˜
# def categorize_response(user_input, categories):
#     # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ (LLMì„ ì‚¬ìš©í•œ ë¶„ì„ìœ¼ë¡œ êµì²´ ê°€ëŠ¥)
#     if "ê¸°ìˆ " in user_input:
#         return "ê¸°ìˆ "
#     elif "ë¬¸í•™" in user_input:
#         return "ë¬¸í•™"
#     elif "ì„±ê³µ" in user_input or "ìê¸°ê³„ë°œ" in user_input:
#         return "ìê¸°ê³„ë°œ"
#     else:
#         return "ê¸°íƒ€"

# ì±… ì¶”ì²œ ìƒì„± í•¨ìˆ˜
def recommend_books(category, df):
    # ì¹´í…Œê³ ë¦¬ì— ë§ëŠ” ì±… í•„í„°ë§
    filtered_books = df[df['category'] == category]
    
    # ì¶”ì²œ ë„ì„œ ëª©ë¡ ìƒì„±
    books_list = "\n".join(
        [
            f"- {row['ì œëª©']} by {row['ì €ì']} (â‚©{row['ê°€ê²©']}): {row['ì„œí‰']}\n"
            f"  êµ¬ë§¤ ë§í¬: {row['Link']}"
            for _, row in filtered_books.iterrows()
        ]
    )
    
    return f"ë‹¤ìŒì€ '{category}' ì¹´í…Œê³ ë¦¬ì—ì„œ ì¶”ì²œí•˜ëŠ” ë„ì„œ ëª©ë¡ì…ë‹ˆë‹¤:\n{books_list}"

# ì±… ì¶”ì²œì— ì‚¬ìš©ëœ í•µì‹¬ í•¨ìˆ˜

def recommend_books(category, df):
    # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ì±… í•„í„°ë§
    filtered_books = df[df['category'] == category]

    # í•„í„°ë§ëœ ì±… ë¦¬ìŠ¤íŠ¸ ìƒì„±
    books_list = "\n".join(
        [
            f"- {row['ì œëª©']} by {row['ì €ì']} (â‚©{row['ê°€ê²©']}): {row['ì„œí‰']}\n"
            f"  ì±… ì„¤ëª…: {row['ì„œí‰']}\n"
            f"  êµ¬ë§¤ ë§í¬: {row['Link']}"
            for _, row in filtered_books.iterrows()
        ]
    )


    # LLMì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = f"""
    ë‹¤ìŒì€ '{category}' ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ì¶”ì²œ ë„ì„œ ëª©ë¡ì…ë‹ˆë‹¤:
    {books_list}

    ì‚¬ìš©ìê°€ ì´ ì¹´í…Œê³ ë¦¬ì— í¥ë¯¸ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ ëª©ë¡ì— ìˆëŠ” ì±…ë§Œì„ ì‚¬ìš©í•´ì„œ ì‚¬ìš©ìì—ê²Œ ì±…ì„ ì¶”ì²œí•´ ì£¼ì„¸ìš”.

    ë‹µë³€ì˜ í˜•ì‹ì€ ì´ì²˜ëŸ¼ í•´ì£¼ì„¸ìš”

    "


    ì§€ê¸ˆ ~~~~í•œ ê³ ë¯¼ì„ ì•ˆê³  ìˆêµ°ìš”. í•µì‹¬ì ì¸ ì›ì¸ì€ ~~ê°™ì•„ìš”

    ë‹¹ì‹ ì˜ ê³ ë¯¼ì„ í•´ê²°í•´ì¤„ ìˆ˜ ìˆëŠ” ìµœê·¼ ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì±…ì€  ì´ì™€ ê°™ì•„ìš”
    1 (ì±…ì˜ ì œëª©) (ì±…ì˜ ì €ì) (ì±…ì˜ ê°€ê²©)
    => ì¶”ì²œ ì´ìœ  (ì¶”ì²œ ì´ìœ ëŠ” í•´ê²°ì±… ìœ„ì£¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”)
    => ì±…ì˜ ì†Œê°œ: (ì±…ì˜ ì†Œê°œë¬¸ì€ 3ì¤„ ì´ìƒ)
    2 (ì±…ì˜ ì œëª©) (ì±…ì˜ ì €ì) (ì±…ì˜ ê°€ê²©) (ì±…ì˜ ì†Œê°œë¬¸)
    => ì¶”ì²œ ì´ìœ 
    3 (ì±…ì˜ ì œëª©) (ì±…ì˜ ì €ì) (ì±…ì˜ ê°€ê²©) (ì±…ì˜ ì†Œê°œë¬¸)
    => ì¶”ì²œ ì´ìœ "


    """

    messages.append(prompt)
    res = llm.invoke(messages)

    print(res.content)



# Show title and description.
st.title("ğŸ’¬ ì±… ì†ì— ë‹µì´ ìˆë‹¤")
st.write(
    "ê°ì ê³ ë¯¼ì˜ ë¬´ê²Œë¥¼ ê²¬ë””ë©° ì‚´ì•„ê°€ëŠ” í˜„ëŒ€ì¸ë“¤. ì¹œêµ¬ë‚˜ ë™ë£Œì—ê²Œ ìì‹ ì˜ ê³ ë¯¼ì„ ë§í•´ë³´ì•„ë„, í•´ê²°ë˜ëŠ” ê²ƒ ê°™ì§€ ì•Šì„ ë•Œ. ê°™ì€ ê³ ë¯¼ì„ í•˜ëŠ” ì‚¬ëŒë“¤ì€ ì–´ë–¤ ì±…ì—ì„œ í•´ê²°ì˜ ì‹¤ë§ˆë¦¬ë¥¼ ì–»ê³  ìˆì„ê¹Œ?"
    "ê³ ë¯¼ì„ ë§í•˜ë©´ ìµœê·¼ ë² ìŠ¤íŠ¸ì…€ëŸ¬ 100ê¶Œ ì¤‘ì—ì„œ ì–»ì„ ìˆ˜ ìˆëŠ” ì§€í˜œë¥¼ ì•Œì•„ì„œ ë‚˜ëˆ ì£¼ëŠ” ì±—ë´‡ì´ ìˆë‹¤ë©´?! ë‹¹ì¥ ì‚¬ìš©í•´ë³´ì. "
    "ì•„ë˜ ëŒ€í™”ì°½ì„ í†µí•´ ëŒ€í™”ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”."
)

# Create an OpenAI client.
!pip install -qU langchain-openai langchain-community chromadb
!pip install openai==1.55.3 httpx==0.27.2 --force-reinstall --quiet
import os
os.kill(os.getpid(), 9)
import os
from langchain_openai import ChatOpenAI
# lanchain_openai: APIë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œ ë³¸ë˜ í•„ìš”í•œ ì£¼ì†Œ, íŒŒë¼ë¯¸í„° ë“± ìˆ˜ì‘ì—…ì„ ìë™í™”.

os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY") or "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" #"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"


llm = ChatOpenAI(
    openai_api_key=os.environ["OPENAI_API_KEY"],
    model_name='gpt-4o-mini' # ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ í•˜ê³  ì‹¶ë‹¤ë©´ 50
)

from langchain.schema import (
    SystemMessage,
    HumanMessage,
    AIMessage
)

messages = [
    SystemMessage(content="You are a helpful assistant."),
    HumanMessage(content="ì•ˆë…•? ì˜¤ëŠ˜ ê¸°ë¶„ì€ ì–´ë•Œ?"),
    AIMessage(content="I'm great thank you. How can I help you?"),
]

# ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
messages = []

# ì‚¬ìš©ìì—ê²Œ ê³ ë¯¼ì„ ë¬¼ì–´ë³´ê¸°

user_input = st.chat_input("ë‹¹ì‹ ì˜ ê³ ë¯¼ì´ë‚˜ í˜„ì¬ ìƒí™©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”: ")

# ì¹´í…Œê³ ë¦¬ ë¶„ì„
matched_category = categorize_response(user_input, categories)

# ê²°ê³¼ ì¶œë ¥
if matched_category == "ê¸°íƒ€":
    prompt = HumanMessage(
    content= user_input
    )

    messages.append(prompt)
    res = llm.invoke(messages)

    st.chat_message("assistant").markdown(res.content)
else:
    recommendation = recommend_books(matched_category, df)
    st.chat_message("assistant").markdown(recommendation)




#ì—¬ê¸°ì„œë¶€í„°ì„
# client = OpenAI(api_key="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")

# # Create a session state variable to store the chat messages. This ensures that the
# # messages persist across reruns.
# if "messages" not in st.session_state:
#     st.session_state.messages = []

# # Display the existing chat messages via `st.chat_message`.
# for message in st.session_state.messages:
#     with st.chat_message(message["role"]):
#         st.markdown(message["content"])


# # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
# user_input = st.chat_input("ë‹¹ì‹ ì˜ ê³ ë¯¼ì´ë‚˜ í˜„ì¬ ìƒí™©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”:")
# if user_input:
#     # ì¹´í…Œê³ ë¦¬ ë¶„ì„
#     df = load_books()
#     categories = df["category"].unique()
#     matched_category = categorize_response(user_input, categories)
    
#     # ê²°ê³¼ ì²˜ë¦¬
#     if matched_category == "ê¸°íƒ€":
#         st.chat_message("assistant").markdown(
#             "ë‹¹ì‹ ì˜ ê³ ë¯¼ì— ëŒ€í•´ ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´, ì í•©í•œ ì¶”ì²œì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
#         )
#     else:
#         recommendation = recommend_books(matched_category, df)
#         st.chat_message("assistant").markdown(recommendation)

# # Create a chat input field to allow the user to enter a message. This will display
# # automatically at the bottom of the page.
# if prompt := st.chat_input("What is up?"):

#     # ë¯¸ë¦¬ í•™ìŠµì‹œí‚¤ê¸°
#     # prompt = f"""
#     # ë‹¤ìŒì€ '{category}' ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ì¶”ì²œ ë„ì„œ ëª©ë¡ì…ë‹ˆë‹¤:
#     # {books_list}

#     # ì‚¬ìš©ìê°€ ì´ ì¹´í…Œê³ ë¦¬ì— í¥ë¯¸ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ ëª©ë¡ì— ìˆëŠ” ì±…ë§Œì„ ì‚¬ìš©í•´ì„œ ì‚¬ìš©ìì—ê²Œ ì±…ì„ ì¶”ì²œí•´ ì£¼ì„¸ìš”.

#     # ë‹µë³€ì˜ í˜•ì‹ì€ ì´ì²˜ëŸ¼ í•´ì£¼ì„¸ìš”

#     # "


#     # ì§€ê¸ˆ ~~~~í•œ ê³ ë¯¼ì„ ì•ˆê³  ìˆêµ°ìš”. í•µì‹¬ì ì¸ ì›ì¸ì€ ~~ê°™ì•„ìš”

#     # ë‹¹ì‹ ì˜ ê³ ë¯¼ì„ í•´ê²°í•´ì¤„ ìˆ˜ ìˆëŠ” ìµœê·¼ ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì±…ì€  ì´ì™€ ê°™ì•„ìš”
#     # 1 (ì±…ì˜ ì œëª©) (ì±…ì˜ ì €ì) (ì±…ì˜ ê°€ê²©)
#     # => ì¶”ì²œ ì´ìœ  (ì¶”ì²œ ì´ìœ ëŠ” í•´ê²°ì±… ìœ„ì£¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”)
#     # => ì±…ì˜ ì†Œê°œ: (ì±…ì˜ ì†Œê°œë¬¸ì€ 3ì¤„ ì´ìƒ)
#     # 2 (ì±…ì˜ ì œëª©) (ì±…ì˜ ì €ì) (ì±…ì˜ ê°€ê²©) (ì±…ì˜ ì†Œê°œë¬¸)
#     # => ì¶”ì²œ ì´ìœ 
#     # 3 (ì±…ì˜ ì œëª©) (ì±…ì˜ ì €ì) (ì±…ì˜ ê°€ê²©) (ì±…ì˜ ì†Œê°œë¬¸)
#     # => ì¶”ì²œ ì´ìœ "


#     # """

#     # Store and display the current prompt.
#     st.session_state.messages.append({"role": "user", "content": prompt})
#     with st.chat_message("user"):
#         st.markdown(prompt)

#     # Generate a response using the OpenAI API.
#     stream = client.chat.completions.create(
#         model="gpt-3.5-turbo",
#         messages=[
#             {"role": m["role"], "content": m["content"]}
#             for m in st.session_state.messages
#         ],
#         stream=True,
#     )

#     # Stream the response to the chat using `st.write_stream`, then store it in 
#     # session state.
#     with st.chat_message("assistant"):
#         response = st.write_stream(stream)
#     st.session_state.messages.append({"role": "assistant", "content": response})
